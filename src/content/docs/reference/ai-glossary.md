---
title: "AI & LLM Glossary: Essential Terms Defined"
description: "Comprehensive glossary of AI, machine learning, and LLM terminology"
sidebar:
  badge:
    text: "Reference"
    variant: note
version: "1.0"
---

# AI & LLM Glossary

## Core AI Concepts

**Artificial Intelligence (AI)**: Systems that simulate human intelligence

**Machine Learning (ML)**: AI systems that learn from data

**Deep Learning**: ML using neural networks with multiple layers

**Neural Network**: Computing systems inspired by biological brains

**Training**: Process of teaching an AI model using data

**Inference**: Using a trained model to make predictions

**Fine-Tuning**: Adapting a pre-trained model to specific tasks

## LLM-Specific Terms

**Large Language Model (LLM)**: AI trained on vast text to understand and generate language

**Transformer**: Neural network architecture powering modern LLMs

**Token**: Basic unit of text (word, subword, or character)

**Context Window**: Maximum tokens an LLM can process at once

**Temperature**: Controls randomness (0=deterministic, 2=creative)

**Top-P (Nucleus Sampling)**: Sampling method for generation

**Prompt**: Input text given to an LLM

**Completion**: LLM's generated response

**System Prompt**: Instructions defining LLM behavior

## Advanced Concepts

**RAG (Retrieval-Augmented Generation)**: Enhancing LLMs with external knowledge retrieval

**Embedding**: Numerical representation of text

**Vector Database**: Stores embeddings for similarity search

**Semantic Search**: Finding meaning, not just keywords

**Hallucination**: When LLM generates false information

**Few-Shot Learning**: Learning from a few examples

**Zero-Shot Learning**: Performing tasks without examples

**Chain-of-Thought**: Step-by-step reasoning approach

**Agent**: AI system that can take actions

**Tool Use**: LLM calling external functions/APIs

## Model Components

**Parameters**: Learned values in neural network

**Layers**: Levels of processing in neural network

**Attention Mechanism**: How models focus on relevant information

**Tokenizer**: Converts text to tokens

**Vocabulary**: All tokens a model knows

**Hidden State**: Internal model representations

## Training Concepts

**Pre-training**: Initial training on large datasets

**Supervised Learning**: Training with labeled data

**Unsupervised Learning**: Training on unlabeled data

**Reinforcement Learning**: Learning through rewards

**RLHF** (Reinforcement Learning from Human Feedback): Training using human preferences

**Overfitting**: Model memorizes training data

**Underfitting**: Model too simple to learn patterns

**Generalization**: Performing well on new data

## Evaluation Metrics

**Perplexity**: How well model predicts text

**BLEU**: Machine translation quality

**ROUGE**: Summarization quality

**F1 Score**: Classification performance

**Accuracy**: Correct predictions percentage

**Precision**: True positives / predicted positives

**Recall**: True positives / actual positives

## API & Deployment

**API** (Application Programming Interface): Interface for software interaction

**Endpoint**: API access point

**Latency**: Response time

**Throughput**: Requests handled per unit time

**Rate Limit**: Maximum requests allowed

**Batch Processing**: Processing multiple items together

**Streaming**: Real-time token-by-token output

**Caching**: Storing results for reuse

## Specialized Terms

**Multimodal**: Processing multiple data types (text, image, audio)

**Vision Model**: Processes images

**Whisper**: OpenAI's speech recognition

**DALL-E**: OpenAI's image generation

**GPT**: Generative Pre-trained Transformer

**BERT**: Bidirectional Encoder Representations from Transformers

**LoRA** (Low-Rank Adaptation): Efficient fine-tuning method

**Quantization**: Reducing model size/precision

**Distillation**: Creating smaller model from larger one

## Ethical & Safety

**Bias**: Unfair preferences in model outputs

**Fairness**: Equitable treatment across groups

**Alignment**: Matching AI behavior with human values

**Safety**: Preventing harmful outputs

**Red Teaming**: Testing for vulnerabilities

**Content Policy**: Rules for allowed outputs

**Moderation**: Filtering inappropriate content

## Business Terms

**Token Cost**: Pricing per token used

**Context Length**: Maximum conversation history

**Fine-Tuning Cost**: Price to customize models

**Inference Cost**: Cost per API call

**ROI** (Return on Investment): Value gained vs cost

**SLA** (Service Level Agreement): Guaranteed uptime/performance

---

**Found an issue?** [Open an issue](https://github.com/javirub/The-New-Era-Codex/issues)!
